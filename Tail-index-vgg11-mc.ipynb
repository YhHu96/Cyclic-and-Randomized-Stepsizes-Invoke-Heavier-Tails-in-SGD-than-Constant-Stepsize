{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ad34cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51af2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corollary 2.4 in Mohammadi 2014 - for 1d\n",
    "def alpha_estimator_one(m, X):\n",
    "    N = len(X)\n",
    "    n = int(N/m) # must be an integer\n",
    "    \n",
    "    X = X[0:n*m]\n",
    "    \n",
    "    Y = np.sum(X.reshape(n, m),1)\n",
    "    eps = np.spacing(1)\n",
    "\n",
    "    Y_log_norm =  np.log(np.abs(Y) + eps).mean()\n",
    "    X_log_norm =  np.log(np.abs(X) + eps).mean()\n",
    "    diff = (Y_log_norm - X_log_norm) / math.log(m)\n",
    "    return 1 / diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16e6c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corollary 2.4 in Mohammadi 2014 - for multi-d\n",
    "def alpha_estimator_multi(m, X):\n",
    "    # X is N by d matrix\n",
    "    N = X.size()[0]   \n",
    "    n = int(N/m) # must be an integer\n",
    "#     print(N,n)\n",
    "    X = X[0:n*m,:]\n",
    "#     print(X.size())\n",
    "    Y = torch.sum(X.view(n, m, -1), 1)\n",
    "    eps = np.spacing(1)\n",
    "    Y_log_norm = torch.log(Y.norm(dim=1) + eps).mean()\n",
    "    X_log_norm = torch.log(X.norm(dim=1) + eps).mean()\n",
    "    diff = (Y_log_norm - X_log_norm) / math.log(m)\n",
    "    return 1 / diff.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "446b53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VGG11/13/16/19 in Pytorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = VGG('VGG11')\n",
    "    x = torch.randn(2,3,32,32)\n",
    "    y = net(x)\n",
    "    print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a8476fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net = VGG(\"VGG11\")\n",
    "for ix, p in enumerate(net.parameters()):\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bd51962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alphas_centralized(etas, PATH, depth):\n",
    "#     alphas_mc    = np.zeros((len(etas), depth))-1\n",
    "    alphas_multi = np.zeros((len(etas), depth))-1\n",
    "#     alphas_single= np.zeros(len(etas))-1\n",
    "#     alphas_haus    = np.zeros((len(etas), depth))-1\n",
    "#     print(num_nets)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ei, eta in tqdm(enumerate(etas)):\n",
    "        \n",
    "        tmp_path = PATH + 'LR{}/'.format(ei)\n",
    "        print(tmp_path)\n",
    "        \n",
    "#         weights = []\n",
    "        weights_unfold = []\n",
    "        weights_unfold_merge = []\n",
    "        for i in range(depth):\n",
    "#             weights.append([])\n",
    "            weights_unfold.append([])\n",
    "\n",
    "        # record the layers in different arrays\n",
    "        for i in range(num_nets):\n",
    "            tmp_path_mod = tmp_path + 'model{}'.format(i+1) +'.pth'\n",
    "            tmp_net = VGG('VGG11')\n",
    "            tmp_net = torch.load(tmp_path_mod,map_location='cpu')\n",
    "#             layerwise_list = get_layerWise(tmp_net)\n",
    "            for ix, p in enumerate(tmp_net.parameters()):\n",
    "                if not (ix % 4 == 0):\n",
    "                    continue\n",
    "                layer = p.detach().numpy()#.astype(np.float16)\n",
    "                if(i == 0):\n",
    "                    weights_unfold[ix//4] = layer / (num_nets * 1.0)\n",
    "                else:\n",
    "                    weights_unfold[ix//4] += layer / (num_nets * 1.0)\n",
    "\n",
    "\n",
    "                layer = layer.reshape(-1,1)\n",
    "#                 weights[ix].append(layer)\n",
    "\n",
    "#         for i in range(depth):\n",
    "#             weights[i] = np.concatenate(weights[i], axis = 1).astype(np.float16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(depth):\n",
    "#             print(weights_unfold[i].shape)\n",
    "#             print(i)\n",
    "            tmp_mean    = np.mean(weights_unfold[i], axis=0)\n",
    "            \n",
    "#             tmp_mean    = tmp_mean[..., np.newaxis]\n",
    "            tmp_mean = tmp_mean[np.newaxis,...]\n",
    "#             print(tmp_mean.shape)\n",
    "#             tmp_weights = weights_unfold[i] - tmp_mean.T\n",
    "            tmp_weights = weights_unfold[i] - tmp_mean\n",
    "#             print(tmp_weights.shape)\n",
    "#             print(len(tmp_weights.shape))\n",
    "            if len(tmp_weights.shape) == 4:\n",
    "#                 print('yes')\n",
    "                tmp_weights = np.reshape(tmp_weights, (tmp_weights.shape[0] * tmp_weights.shape[1], -1))\n",
    "#                 print(tmp_weights.shape)\n",
    "            \n",
    "            alphas_multi[ei,i] = np.median([alpha_estimator_multi(mm, torch.from_numpy(tmp_weights)) for mm in (2, 5, 10)])\n",
    "\n",
    "\n",
    "\n",
    "#         for i in range(depth):\n",
    "#             tmp_mean    = np.mean(weights[i], axis=1)\n",
    "#             tmp_mean    = tmp_mean[..., np.newaxis]\n",
    "#             tmp_weights = weights[i] - tmp_mean\n",
    "#             tmp_weights = tmp_weights.reshape(-1,1)     \n",
    "#             tmp_alphas = [alpha_estimator_one(mm, tmp_weights) for mm in (2, 5, 10, 20, 50, 100, 500, 1000)]\n",
    "#             alphas_haus[ei,i] = np.median(tmp_alphas)\n",
    "# #             print(tmp_alphas)\n",
    "\n",
    "\n",
    "#         for i in range(depth):\n",
    "#             tmp_weights = np.mean(weights[i], axis=1)\n",
    "#             tmp_weights = tmp_weights.reshape(-1,1)\n",
    "#             tmp_weights = tmp_weights - np.mean(tmp_weights)\n",
    "#             tmp_alphas = [alpha_estimator_one(mm, tmp_weights) for mm in (2, 5, 10, 20, 50, 100, 500, 1000)]\n",
    "#             alphas_mc[ei,i] = np.median(tmp_alphas)\n",
    "\n",
    "\n",
    "\n",
    "    return alphas_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c475134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./VGG-CIFAR10-mc-umut/LR0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:25, 145.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./VGG-CIFAR10-mc-umut/LR1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [04:39, 139.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./VGG-CIFAR10-mc-umut/LR2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [07:00, 139.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./VGG-CIFAR10-mc-umut/LR3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [09:41, 145.37s/it]\n"
     ]
    }
   ],
   "source": [
    "PATH = './VGG-CIFAR10-mc-umut/'\n",
    "lr_list = [0.005, 0.01, 0.015, 0.02]\n",
    "\n",
    "depth = 9\n",
    "num_nets = 100\n",
    "nets = []\n",
    "alphas_mc_cent = compute_alphas_centralized(lr_list, PATH, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27a29dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.70131078, 1.84948065, 1.97705086, 1.9826596 , 2.01181858,\n",
       "        2.01008661, 2.02033179, 2.01426415, 2.24503904],\n",
       "       [1.69895342, 1.76898122, 1.96999567, 1.95056214, 1.99942844,\n",
       "        1.98421448, 2.00369371, 1.98654843, 2.23508928],\n",
       "       [1.5619682 , 1.70205866, 1.9328316 , 1.96690041, 2.00316237,\n",
       "        1.98376894, 1.98317333, 1.94923005, 2.24730152],\n",
       "       [1.49507248, 1.76525402, 1.91523354, 1.95274481, 1.96527976,\n",
       "        1.97075261, 1.97475589, 1.9161435 , 2.2446439 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_mc_cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7fac2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.01008661, 1.98421448, 1.96690041, 1.95274481])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(alphas_mc_cent, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65f79ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.97911578, 1.95527409, 1.92559945, 1.91109784])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(alphas_mc_cent, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "907e4884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.70131078, 1.69895342, 1.5619682 , 1.49507248])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(alphas_mc_cent, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe584d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
