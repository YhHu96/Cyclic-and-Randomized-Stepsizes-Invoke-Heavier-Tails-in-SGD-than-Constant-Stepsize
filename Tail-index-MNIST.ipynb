{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corollary 2.4 in Mohammadi 2014 - for 1d\n",
    "def alpha_estimator_one(m, X):\n",
    "    N = len(X)\n",
    "    n = int(N/m) # must be an integer\n",
    "    \n",
    "    X = X[0:n*m]\n",
    "    \n",
    "    Y = np.sum(X.reshape(n, m),1)\n",
    "    eps = np.spacing(1)\n",
    "\n",
    "    Y_log_norm =  np.log(np.abs(Y) + eps).mean()\n",
    "    X_log_norm =  np.log(np.abs(X) + eps).mean()\n",
    "    diff = (Y_log_norm - X_log_norm) / math.log(m)\n",
    "    return 1 / diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corollary 2.4 in Mohammadi 2014 - for multi-d\n",
    "def alpha_estimator_multi(m, X):\n",
    "    # X is N by d matrix\n",
    "    N = X.size()[0]   \n",
    "    n = int(N/m) # must be an integer\n",
    "#     print(N,n)\n",
    "    X = X[0:n*m,:]\n",
    "#     print(X.size())\n",
    "    Y = torch.sum(X.view(n, m, -1), 1)\n",
    "    eps = np.spacing(1)\n",
    "    Y_log_norm = torch.log(Y.norm(dim=1) + eps).mean()\n",
    "    X_log_norm = torch.log(X.norm(dim=1) + eps).mean()\n",
    "    diff = (Y_log_norm - X_log_norm) / math.log(m)\n",
    "    return 1 / diff.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple FCN\n",
    "class simpleNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=28*28 , width=128, depth=3, num_classes=10):\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        layers = self.get_layers()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.width, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            *layers,\n",
    "            nn.Linear(self.width, self.num_classes, bias=False),\n",
    "        )\n",
    "\n",
    "    def get_layers(self):\n",
    "        layers = []\n",
    "        for i in range(self.depth - 2):\n",
    "            layers.append(nn.Linear(self.width, self.width, bias=False))\n",
    "            layers.append(nn.ReLU())\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), self.input_dim)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './3FCN-MNIST/'\n",
    "# lr_list = np.linspace(0.001,0.1,20)\n",
    "lr_list = [0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12]\n",
    "\n",
    "depth = 3\n",
    "num_nets = 1000\n",
    "nets = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layerWise(net):\n",
    "    w = []\n",
    "    flag=0\n",
    "    for p in net.parameters():    \n",
    "        if p.requires_grad:\n",
    "            if flag==1:\n",
    "#                 w[-1]=torch.cat((w[-1],p.view(-1,1)),1)\n",
    "                flag=0\n",
    "            else:\n",
    "                flag=1\n",
    "                w.append(p)\n",
    "    for i in range(len(w)):\n",
    "        w[i]=w[i].detach().numpy()\n",
    "    res=np.array(w)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alphas_centralized(etas, PATH, depth):\n",
    "#     alphas_mc    = np.zeros((len(etas), depth))-1\n",
    "    alphas_multi = np.zeros((len(etas), depth))-1\n",
    "#     alphas_single= np.zeros(len(etas))-1\n",
    "#     alphas_haus    = np.zeros((len(etas), depth))-1\n",
    "#     print(num_nets)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ei, eta in tqdm(enumerate(etas)):\n",
    "        \n",
    "        tmp_path = PATH + 'LR{}/'.format(ei)\n",
    "        print(tmp_path)\n",
    "        \n",
    "#         weights = []\n",
    "        weights_unfold = []\n",
    "        weights_unfold_merge = []\n",
    "        for i in range(depth):\n",
    "#             weights.append([])\n",
    "            weights_unfold.append([])\n",
    "\n",
    "        # record the layers in different arrays\n",
    "        for i in range(num_nets):\n",
    "            tmp_path_mod = tmp_path + 'model{}'.format(i+1) +'.pth'\n",
    "            tmp_net = simpleNet()\n",
    "            tmp_net = torch.load(tmp_path_mod,map_location='cpu')\n",
    "#             layerwise_list = get_layerWise(tmp_net)\n",
    "            for ix, p in enumerate(tmp_net.parameters()):\n",
    "                if not (ix % 2 == 0):\n",
    "                    continue\n",
    "                layer = p.detach().numpy()#.astype(np.float16)\n",
    "                if(i == 0):\n",
    "                    weights_unfold[ix//2] = layer / (num_nets * 1.0)\n",
    "                else:\n",
    "                    weights_unfold[ix//2] += layer / (num_nets * 1.0)\n",
    "\n",
    "\n",
    "                layer = layer.reshape(-1,1)\n",
    "#                 weights[ix].append(layer)\n",
    "\n",
    "#         for i in range(depth):\n",
    "#             weights[i] = np.concatenate(weights[i], axis = 1).astype(np.float16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(depth):\n",
    "#             print(weights_unfold[i].shape)\n",
    "#             print(i)\n",
    "            tmp_mean    = np.mean(weights_unfold[i], axis=0)\n",
    "            \n",
    "#             tmp_mean    = tmp_mean[..., np.newaxis]\n",
    "            tmp_mean = tmp_mean[np.newaxis,...]\n",
    "#             print(tmp_mean.shape)\n",
    "#             tmp_weights = weights_unfold[i] - tmp_mean.T\n",
    "            tmp_weights = weights_unfold[i] - tmp_mean\n",
    "#             print(tmp_weights.shape)\n",
    "#             print(len(tmp_weights.shape))\n",
    "            if len(tmp_weights.shape) == 4:\n",
    "#                 print('yes')\n",
    "                tmp_weights = np.reshape(tmp_weights, (tmp_weights.shape[0] * tmp_weights.shape[1], -1))\n",
    "#                 print(tmp_weights.shape)\n",
    "            \n",
    "            alphas_multi[ei,i] = np.median([alpha_estimator_multi(mm, torch.from_numpy(tmp_weights)) for mm in (2, 5, 10)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return alphas_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "tmp_mod = simpleNet()\n",
    "idx = 0\n",
    "for i in tmp_mod.parameters():\n",
    "    print(i.shape)\n",
    "#     print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CNN-CIFAR10-unif/LR0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CNN-CIFAR10-unif/LR1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:14,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CNN-CIFAR10-unif/LR2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:21,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CNN-CIFAR10-unif/LR3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:28,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CNN-CIFAR10-unif/LR4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:36,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CNN-CIFAR10-unif/LR5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:43,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CNN-CIFAR10-unif/LR6/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:50,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CNN-CIFAR10-unif/LR7/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:58,  7.30s/it]\n"
     ]
    }
   ],
   "source": [
    "PATH = './3FCN-MNIST-unif/'\n",
    "lr_list = [0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12]\n",
    "\n",
    "depth = 3\n",
    "num_nets = 1000\n",
    "nets = []\n",
    "alphas_mc_cent = compute_alphas_centralized(lr_list, PATH, depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.75965741, 2.10764968, 2.08125705, 2.10009752, 2.32603469],\n",
       "       [1.72196667, 1.88239159, 2.0448582 , 2.09197958, 1.95549839],\n",
       "       [1.66763325, 1.97760457, 2.05219056, 2.06174552, 1.94725793],\n",
       "       [1.52074925, 1.9689747 , 2.0669305 , 1.98348258, 2.01566   ],\n",
       "       [1.69568467, 2.12406174, 2.04512429, 2.1079554 , 2.05447616],\n",
       "       [1.69549531, 2.12672936, 2.04408338, 2.03716302, 1.84752138],\n",
       "       [1.76361753, 2.07184698, 2.03102426, 2.10495943, 1.96493566],\n",
       "       [1.63770094, 2.1224194 , 2.03361919, 1.97968842, 1.82101094]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_mc_cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.07493927, 1.93933889, 1.94128636, 1.91115941, 2.00546045,\n",
       "       1.95019849, 1.98727677, 1.91888778])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(alphas_mc_cent, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
