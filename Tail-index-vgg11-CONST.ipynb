{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cef796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb53a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corollary 2.4 in Mohammadi 2014 - for 1d\n",
    "def alpha_estimator_one(m, X):\n",
    "    N = len(X)\n",
    "    n = int(N/m) # must be an integer\n",
    "    \n",
    "    X = X[0:n*m]\n",
    "    \n",
    "    Y = np.sum(X.reshape(n, m),1)\n",
    "    eps = np.spacing(1)\n",
    "\n",
    "    Y_log_norm =  np.log(np.abs(Y) + eps).mean()\n",
    "    X_log_norm =  np.log(np.abs(X) + eps).mean()\n",
    "    diff = (Y_log_norm - X_log_norm) / math.log(m)\n",
    "    return 1 / diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8223f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corollary 2.4 in Mohammadi 2014 - for multi-d\n",
    "def alpha_estimator_multi(m, X):\n",
    "    # X is N by d matrix\n",
    "    N = X.size()[0]   \n",
    "    n = int(N/m) # must be an integer\n",
    "#     print(N,n)\n",
    "    X = X[0:n*m,:]\n",
    "#     print(X.size())\n",
    "    Y = torch.sum(X.view(n, m, -1), 1)\n",
    "    eps = np.spacing(1)\n",
    "    Y_log_norm = torch.log(Y.norm(dim=1) + eps).mean()\n",
    "    X_log_norm = torch.log(X.norm(dim=1) + eps).mean()\n",
    "    diff = (Y_log_norm - X_log_norm) / math.log(m)\n",
    "    return 1 / diff.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b7746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VGG11/13/16/19 in Pytorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = VGG('VGG11')\n",
    "    x = torch.randn(2,3,32,32)\n",
    "    y = net(x)\n",
    "    print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0943524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net = VGG(\"VGG11\")\n",
    "for ix, p in enumerate(net.parameters()):\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fc6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alphas_centralized(etas, PATH, depth):\n",
    "#     alphas_mc    = np.zeros((len(etas), depth))-1\n",
    "    alphas_multi = np.zeros((len(etas), depth))-1\n",
    "#     alphas_single= np.zeros(len(etas))-1\n",
    "#     alphas_haus    = np.zeros((len(etas), depth))-1\n",
    "#     print(num_nets)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ei, eta in tqdm(enumerate(etas)):\n",
    "        \n",
    "        tmp_path = PATH + 'LR{}/'.format(ei)\n",
    "        print(tmp_path)\n",
    "        \n",
    "#         weights = []\n",
    "        weights_unfold = []\n",
    "        weights_unfold_merge = []\n",
    "        for i in range(depth):\n",
    "#             weights.append([])\n",
    "            weights_unfold.append([])\n",
    "\n",
    "        # record the layers in different arrays\n",
    "        for i in range(num_nets):\n",
    "            tmp_path_mod = tmp_path + 'model{}'.format(i+1) +'.pth'\n",
    "            tmp_net = VGG('VGG11')\n",
    "            tmp_net = torch.load(tmp_path_mod,map_location='cpu')\n",
    "#             layerwise_list = get_layerWise(tmp_net)\n",
    "            for ix, p in enumerate(tmp_net.parameters()):\n",
    "                if not (ix % 4 == 0):\n",
    "                    continue\n",
    "                layer = p.detach().numpy()#.astype(np.float16)\n",
    "                if(i == 0):\n",
    "                    weights_unfold[ix//4] = layer / (num_nets * 1.0)\n",
    "                else:\n",
    "                    weights_unfold[ix//4] += layer / (num_nets * 1.0)\n",
    "\n",
    "\n",
    "                layer = layer.reshape(-1,1)\n",
    "#                 weights[ix].append(layer)\n",
    "\n",
    "#         for i in range(depth):\n",
    "#             weights[i] = np.concatenate(weights[i], axis = 1).astype(np.float16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(depth):\n",
    "#             print(weights_unfold[i].shape)\n",
    "#             print(i)\n",
    "            tmp_mean    = np.mean(weights_unfold[i], axis=0)\n",
    "            \n",
    "#             tmp_mean    = tmp_mean[..., np.newaxis]\n",
    "            tmp_mean = tmp_mean[np.newaxis,...]\n",
    "#             print(tmp_mean.shape)\n",
    "#             tmp_weights = weights_unfold[i] - tmp_mean.T\n",
    "            tmp_weights = weights_unfold[i] - tmp_mean\n",
    "#             print(tmp_weights.shape)\n",
    "#             print(len(tmp_weights.shape))\n",
    "            if len(tmp_weights.shape) == 4:\n",
    "#                 print('yes')\n",
    "                tmp_weights = np.reshape(tmp_weights, (tmp_weights.shape[0] * tmp_weights.shape[1], -1))\n",
    "#                 print(tmp_weights.shape)\n",
    "            \n",
    "            alphas_multi[ei,i] = np.median([alpha_estimator_multi(mm, torch.from_numpy(tmp_weights)) for mm in (2, 5, 10)])\n",
    "\n",
    "\n",
    "\n",
    "#         for i in range(depth):\n",
    "#             tmp_mean    = np.mean(weights[i], axis=1)\n",
    "#             tmp_mean    = tmp_mean[..., np.newaxis]\n",
    "#             tmp_weights = weights[i] - tmp_mean\n",
    "#             tmp_weights = tmp_weights.reshape(-1,1)     \n",
    "#             tmp_alphas = [alpha_estimator_one(mm, tmp_weights) for mm in (2, 5, 10, 20, 50, 100, 500, 1000)]\n",
    "#             alphas_haus[ei,i] = np.median(tmp_alphas)\n",
    "# #             print(tmp_alphas)\n",
    "\n",
    "\n",
    "#         for i in range(depth):\n",
    "#             tmp_weights = np.mean(weights[i], axis=1)\n",
    "#             tmp_weights = tmp_weights.reshape(-1,1)\n",
    "#             tmp_weights = tmp_weights - np.mean(tmp_weights)\n",
    "#             tmp_alphas = [alpha_estimator_one(mm, tmp_weights) for mm in (2, 5, 10, 20, 50, 100, 500, 1000)]\n",
    "#             alphas_mc[ei,i] = np.median(tmp_alphas)\n",
    "\n",
    "\n",
    "\n",
    "    return alphas_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f81e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./VGG-CIFAR10-const/LR0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [01:25, 85.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./VGG-CIFAR10-const/LR1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [03:38, 113.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./VGG-CIFAR10-const/LR2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [05:36, 115.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./VGG-CIFAR10-const/LR3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [07:41, 115.35s/it]\n"
     ]
    }
   ],
   "source": [
    "PATH = './VGG-CIFAR10-const/'\n",
    "lr_list = [0.005, 0.01, 0.015, 0.02]\n",
    "\n",
    "depth = 9\n",
    "num_nets = 100\n",
    "nets = []\n",
    "alphas_mc_cent = compute_alphas_centralized(lr_list, PATH, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ecf21d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.43459197, 1.61065861, 1.87028294, 1.91066577, 1.93506916,\n",
       "        1.94733387, 1.94435442, 1.80456754, 2.13461829],\n",
       "       [1.42228299, 1.53848657, 1.78324456, 1.88463322, 1.93756428,\n",
       "        1.95228989, 1.92369153, 1.78013471, 2.11235648],\n",
       "       [1.39116729, 1.6006028 , 1.83778475, 1.90368609, 1.93521737,\n",
       "        1.94304025, 1.91924341, 1.78208268, 2.12290993],\n",
       "       [1.38184235, 1.58372917, 1.84581255, 1.86801186, 1.95520167,\n",
       "        1.9226781 , 1.93092917, 1.75999337, 2.15442469]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_mc_cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0128ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91066577, 1.88463322, 1.90368609, 1.86801186])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(alphas_mc_cent, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f600bb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8435714 , 1.81496491, 1.82619273, 1.82251366])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(alphas_mc_cent, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298cf988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.43459197, 1.42228299, 1.39116729, 1.38184235])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(alphas_mc_cent, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde893c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
